{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754a792-ba2c-4e6f-b64a-0139c107b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import openai\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import gradio as gr\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Database Configuration\n",
    "PGHOST = \"azdailabposdb01.postgres.database.azure.com\"\n",
    "PGUSER = \"devdba\"\n",
    "PGPORT = \"5432\"\n",
    "PGDATABASE = \"doc_proc_dev_db\"\n",
    "PGPASSWORD = \"<YOUR_PASSWORD>\"  # Replace with your actual password\n",
    "\n",
    "# OpenAI Configuration\n",
    "openai.api_base = \"https://rakbankgenaidevai.openai.azure.com/\"\n",
    "openai.api_key = \"db8d369a30e840b39dfdce48087f\"\n",
    "\n",
    "def connect_to_database():\n",
    "    \"\"\"\n",
    "    Establishes a connection to the PostgreSQL database.\n",
    "    Returns the connection object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=PGHOST,\n",
    "            user=PGUSER,\n",
    "            password=PGPASSWORD,\n",
    "            port=PGPORT,\n",
    "            database=PGDATABASE\n",
    "        )\n",
    "        print(\"Database connection successful!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "def query_database(conn, query):\n",
    "    \"\"\"\n",
    "    Executes a query on the database.\n",
    "    :param conn: Database connection object\n",
    "    :param query: SQL query to execute\n",
    "    :return: Query results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None\n",
    "\n",
    "def interact_with_openai(prompt, engine=\"text-davinci-003\", max_tokens=50):\n",
    "    \"\"\"\n",
    "    Sends a prompt to OpenAI and returns the response.\n",
    "    :param prompt: Input prompt for OpenAI API\n",
    "    :param engine: Engine to use for OpenAI\n",
    "    :param max_tokens: Maximum number of tokens in the response\n",
    "    :return: OpenAI API response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error using OpenAI API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Gradio interface\n",
    "def extract_and_answer(file):\n",
    "    \"\"\"\n",
    "    Handles file upload, extracts content, and answers questions.\n",
    "    :param file: The uploaded file\n",
    "    :return: Answers to user questions\n",
    "    \"\"\"\n",
    "    # Save uploaded file temporarily\n",
    "    file_path = file.name\n",
    "    os.rename(file.name, file_path)\n",
    "\n",
    "    # Extract text from PDF or image file\n",
    "    try:\n",
    "        with fitz.open(file_path) as doc:\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "    except Exception as e:\n",
    "        return f\"Error processing file: {e}\"\n",
    "\n",
    "    # Initialize embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = Chroma.from_texts([text], embedding=embeddings)\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    # Load LLM and QA chain\n",
    "    llm = OpenAI(engine=\"text-davinci-003\")\n",
    "    qa_chain = load_qa_chain(llm, retriever)\n",
    "\n",
    "    # Answer user question\n",
    "    question = \"Summarize the document\"  # Example question\n",
    "    response = qa_chain.run(question)\n",
    "    return response\n",
    "\n",
    "def gradio_interface():\n",
    "    \"\"\"\n",
    "    Creates a Gradio interface for document processing and QA.\n",
    "    \"\"\"\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### Document Processor with OpenAI Integration\")\n",
    "        file_input = gr.File(label=\"Upload a PDF or image file\")\n",
    "        question_input = gr.Textbox(label=\"Enter your question\")\n",
    "        submit_button = gr.Button(\"Submit\")\n",
    "        answer_output = gr.Textbox(label=\"Answer\")\n",
    "\n",
    "        def process(file, question):\n",
    "            answer = extract_and_answer(file)\n",
    "            # OpenAI interaction example\n",
    "            if question:\n",
    "                openai_response = interact_with_openai(question)\n",
    "                return f\"Extracted Answer: {answer}\\n\\nOpenAI Response: {openai_response}\"\n",
    "            return answer\n",
    "\n",
    "        submit_button.click(process, inputs=[file_input, question_input], outputs=answer_output)\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "def main():\n",
    "    # Connect to the database\n",
    "    conn = connect_to_database()\n",
    "    if conn:\n",
    "        # Example query\n",
    "        query = \"SELECT * FROM your_table_name LIMIT 5;\"  # Replace 'your_table_name' with the actual table\n",
    "        results = query_database(conn, query)\n",
    "        if results:\n",
    "            print(\"Database Query Results:\")\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        conn.close()\n",
    "\n",
    "    # Launch Gradio interface\n",
    "    gradio_interface()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
